## 线程
* yield方法：当前线程让出CPU执行权，让CPU去执行其他线程，但放弃和重占CPU的时机是不确定的。
* daemon线程：守护线程在所有用户线程结束后，就自动结束

线程状态：
1. NEW：新建状态，还未调用start()开始执行
2. RUNNABLE：Java把Ready（就绪）和Running（执行）两种状态合并为一种
3. BLOCKED：阻塞状态，例如等待锁、IO阻塞
4. WAITING：无限期等待，例如调用join()、wait()、LockSupport.park()
5. TIMED_WAITING：限时等待，例如调用sleep(time)、wait(time)、LockSupport.parkNanos(time)等
6. TERMINATED：终止状态，线程执行结束或者没有处理异常

## 线程池
[Java线程池ThreadPoolExecutor实现原理](https://itimetraveler.github.io/2018/02/13/%E3%80%90Java%E3%80%91%E7%BA%BF%E7%A8%8B%E6%B1%A0ThreadPoolExecutor%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#execute-%E6%96%B9%E6%B3%95)

线程池的关键类是ThreadPoolExecutor

线程复用的关键就是，一个线程循环从BlockingQueue取runnable去调用run执行，即一个线程对应多个runnable

#### execute方法
```
    public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        /*
         * Proceed in 3 steps:
         *
         * 1. If fewer than corePoolSize threads are running, try to
         * start a new thread with the given command as its first
         * task.  The call to addWorker atomically checks runState and
         * workerCount, and so prevents false alarms that would add
         * threads when it shouldn't, by returning false.
         *
         * 2. If a task can be successfully queued, then we still need
         * to double-check whether we should have added a thread
         * (because existing ones died since last checking) or that
         * the pool shut down since entry into this method. So we
         * recheck state and if necessary roll back the enqueuing if
         * stopped, or start a new thread if there are none.
         *
         * 3. If we cannot queue task, then we try to add a new
         * thread.  If it fails, we know we are shut down or saturated
         * and so reject the task.
         */
        int c = ctl.get();
        //1.线程池的线程数小于corePoolSize核心线程数，则开启新核心线程
        if (workerCountOf(c) < corePoolSize) {
            if (addWorker(command, true))//添加新核心线程
                return;
            c = ctl.get();
        }
        2.大于等于corePoolSize核心线程数，或者添加新核心线程失败，则将任务放入阻塞队列中，待某个线程去执行
        if (isRunning(c) && workQueue.offer(command)) {
            //第2步的if内的代码与正常执行的情况无关，放到阻塞队列自然有线程去执行，if内部代码是处理异常情况
            int recheck = ctl.get();
            if (! isRunning(recheck) && remove(command))
                reject(command);//reject方法都会对应到任务拒绝策略
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        //任务队列已满，开启非核心线程执行任务
        else if (!addWorker(command, false))
            reject(command);
    }
```

## 锁
### 1. volatile
* 可见性：读数据时从主内存读取，写值时刷新到主内存
* 禁止指令重排序

### 2. synchronized
经过编译后，会在同步块前后分别形成monitorenter和monitorexit字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。执行monitorenter指令时，首先会尝试获取对象的锁，将锁的计数器加1，相应的，执行monitorexit指令时会将锁计数器减1，计数器为0时锁就会被释放。如果获取对象锁失败，当前线程就会阻塞等待，直到对象锁被另外一个线程释放。

Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态，因此状态转换需要耗费很多的处理器时间。对于synchronized修饰的同步块，状态转换消耗的时间可能比用户代码执行的时间还要长。所以synchronized是Java中的一个重量级操作。但虚拟机本身也会做一些优化，比如在通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁切入到核心态。

* 可重入：是通过记录锁的持有线程和持有数量来实现的
* 可见性：synchronized可以保证可见性

### 3. Lock接口
Lock接口是API层面的互斥锁，相比synchronized，增加了一些高级功能，例如等待可中断，可实现公平锁，锁可以绑定多个条件。

https://www.cnblogs.com/fsmly/p/11274572.html  
https://www.cnblogs.com/waterystone/p/4920797.html

### 4. 非阻塞同步
互斥同步的最大问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称阻塞同步。随着硬件指令集的发展，可以使用基于冲突检测的乐观并发策略，通俗地说，就是现进行操作，如果没有其它线程争用共享数据，就操作成功；如果共享数据有争用，就再采取其他的补偿措施（最常见的就是循环重试），这种乐观并发策略不需要把线程挂起，因此这种同步操作成为非阻塞同步。

乐观并发策略需要硬件指令集的发展，是因为我们需要操作和冲突检测这两个步骤具备原子性，如果再使用同步互斥就没有意义了，所以只能靠硬件保证一个从语义上看起来需要多次操作的行为只通过一条处理器指令就能完成，例如：
* 测试并设置（test and set）
* 获取并增加（fetch and increment）
* 交换（swap）
* 比较并交换（compare and swap，CAS）
* 加载链接/条件存储（load linked/store conditional）

前三条指令是20世纪就已经存在，后面两条指令是现代处理器新增的。CAS指令需要三个操作数，分别是内存位置、旧的预期值和新值。CAS指令执行时，当且仅当内存中的值符合旧预期值时，处理器就用新值更新内存中的值，否则就不执行更新，这个过程是原子操作。

在JDK 1.5之后，Java程序中才可以使用CAS操作，该操作由sun.misc.Unsafe类提供，虚拟机在内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，或者可以认为是内联进去了。例如AtomicInteger的incrementAndGet()方法就会在无限循环中尝试将比自己大1的新值赋值给自己，失败就再次循环尝试，直到成功。

### 5. 无同步方案
使用可重入代码（不依赖共享数据）、线程本地存储等。

## 锁优化
### 1. 适应性自旋
为了让线程等待，只需让线程执行一个忙循环（自旋），这项技术就是自旋锁。自选锁虽然避免了线程切换的开销，但它要占用处理器时间，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，自旋的线程会白白消耗处理器资源。因此，自旋的时间必须有限度，默认循环10次。

JDK 1.6中引入的自适应自旋锁，意味着自旋的时间不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚刚成功获得过的锁，并且持有锁的线程正在运行，那么虚拟机就会认为这次自旋很有可能成功，进而它将允许自旋等待持续更长的时间，比如100个循环。反之，可能自旋时间变短，甚至省略。随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确。

### 2. 锁消除
锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。

### 3. 锁粗化
原则上，推荐将同步块的作用范围限制得尽量小，只在共享数据的实际作用域中才进行同步，这样是为了使需要同步的操作数量变小，如果存在锁竞争，等待锁的线程才能尽快拿到锁。但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作都是出现在循环体中，那么即使没有线程竞争，频繁地互斥同步操作也会导致不必要的性能损耗。

如果虚拟机探测到有一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部，这样就只需要加锁一次。

### 4. 轻量级锁
轻量级锁是JDK 1.6加入的新型锁机制。

HotSpot虚拟机的对象头分为两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码、GC分代年龄等，官方称这部分数据为”Mark Word“，它是实现轻量级锁和偏向锁的关键。另一部分用于存储指向方法区对象类型数据的指针，如果是数组对象的话， 还会有一个额外的部分用于存储数组长度。

|  存储内容   |  标志位 | 状态 |
|  ----  | ----  | ----  |
| 对象哈希码、对象分代年龄  | 01 | 未锁定 |
| 指向锁记录的指针  | 00 | 轻量级锁定 |
| 指向重量级锁的指针  | 10 | 膨胀（重量级锁定） |
| 空，不需要记录信息  | 11 | GC标记 |
| 偏向线程ID、偏向时间戳、对象分代年龄  | 01 | 可偏向 |

首先，多个线程运行到同步块，会检查锁对象状态值标志是否加锁，如果没有锁（锁标志为01）就把锁对象的markword的信息拷贝到自己线程存起来，然后通过cas尝试把对象的mark的值改变成一个指向自己线程的指针，一旦成功其他线程的cas就会失败，因为锁对象的mark已经变成一个新的指针了，必须等待线程释放锁，其他线程才能继续获取。

其他线程通过自旋竞争锁，当自旋次数超过jvm预期上限，就会影响性能，所以竞争的线程就会把锁的对象mark指向重锁，然后所有的竞争线程放弃自旋，进入阻塞状态。

当成功获取锁的线程执行完毕，尝试通过cas释放锁时，因为mark已经指向重锁，也会解锁失败，这时线程就会知道锁已经升级为重量级锁， 它不仅要释放当前锁，还要唤醒其他阻塞的线程。

轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销，但如果存在锁竞争，除了互斥量的开销外，还额外发生CAS操作，因此在有竞争的情况下，轻量级锁比传统的重量级锁更慢。

### 5. 偏向锁
偏向锁也是JDK 1.6引入的一项锁优化。

当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为01，即偏向模式。同时使用CAS操作把获取到这个锁的线程ID记录在对象的Mark Word中，如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作。当有另外一个线程取尝试获取这个锁时，偏向模式就结束了，并且会根据锁对象目前是否处于被锁定的状态，恢复到未锁定（01）或者轻量级锁定（00）的状态，后续的同步操作就跟轻量级锁一样。

偏向锁可以提高无竞争情况的性能，而竞争多的情况下偏向锁就是多余的。

## 可见性与有序性
为了解决内存的可见性问题，CPU主要提供了两种解决办法：总线锁和缓存锁。

在多CPU的系统中，当其中一个CPU要对共享主存进行操作时，在总线上发出一个LOCK#信号，这个信号使得其他CPU无法通过总线来访问共享主存中的数据，总线锁把CPU和主存之间的通信锁住了，这使得锁定期间，其他CPU不能操作其他主存地址的数据，总线锁的开销比较大，这种机制显然是不合适的。

相比总线锁，缓存锁降低了锁的粒度。为了达到数据访问的一致，需要各个CPU在访问高速缓存时遵循一些协议，在存取数据时根据协议来操作，常见的协议有MSI、MESI、MOSI等。最常见的就是MESI协议。

缓存一致性机制就是当某CPU对高速缓存中的数据进行操作之后，通知其他CPU放弃存储在它们内部的缓存数据，或者从主存中重新读取。

在正常情况下，系统操作并不会校验共享变量的缓存一致性，当共享变量用volatile关键字修饰了，该变量所在的缓存行才被要求进行缓存一致性的校验。


JMM（Java内存模型）定义了一套happens before原则（保证可见性和有序性）：
happens-before 8大原则（happens-before可以理解为，A发生于B前，那么B是可以感知A的所有操作修改）
1. 程序次序规则：同一线程按顺序执行
2. volatile变量规则：读取volatile变量前，可以感知任意线程此前对它的修改
3. 传递性规则
4. 锁规则：同一个锁，前一个线程的解锁操作对于后一个线程的加锁操作是可见的。为什么使用锁时的临界区代码具有可见性，因为根据顺序性规则，临界区的修改发生于解锁前，再根据传递性规则，也就发生于另一个线程的加锁前
5. 线程启动规则：A线程调用B线程的start，在B的start前，A的所有操作，B线程都可见
6. 线程join：A线程调用B线程的join，那么B线程的所有操作，在join返回后，A线程都可见
7. 线程中断：调用interrupt，发生在isInterrupted()检测到true之前
8. 对象终结规则：对象的初始化发生在finalize() 方法之前

> 例：如果线程1写入了volatile变量v，接着线程2读取了v，那么线程1写入v及之前的写操作都对线程2可见。也就是说，如果你感知到了volatile变量v的变化，那么在v之前的所有写操作你都可以感知的到。
> 在没 volatile 修饰时，jvm也会尽量保证可见性。​有 volatile 修饰的时候，一定保证可见性

除了long、double，其他基本类型和引用的赋值都是原子的，带volatile的long、double也是原子的。

Lock API的可见性是aqs的volatile修饰的state带来的

JAVA内存模型规定，lock一个变量时需要清空工作内存的缓存，unlock一个变量时需要将工作内存同步回主内存中，synchronzied会遵守这个规定

公平锁在释放锁的最后写volatile变量state，在获取锁时首先读这个volatile变量。根据volatile的happens-before规则，释放锁的线程在写volatile变量之前可见的共享变量，在获取锁的线程读取同一个volatile变量后将立即变得对获取锁的线程可见。从而保证了代码段中变量（变量主要是指共享变量，存在竞争问题的变量）的可见性。


原子性（互斥）还是要锁来保证

System.out.print内部用了锁，会导致测试不出可见性问题，需要注意


AQS锁，使用LockSupport.park来等待，LockSupport.unpark来唤醒

CAS
ThreadLocal
java.util.concurrent包内有Java提供的各种并发编程类

LongAdder
LockSupport

https://juejin.cn/post/6969408505694388237
https://www.kotlincn.net/docs/reference/coroutines/shared-mutable-state-and-concurrency.html
http://www.blogjava.net/xylz/archive/2010/07/08/325587.html
https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzkxODI2MDMzMA==&action=getalbum&album_id=2263501677771161601&scene=173&from_msgid=2247485907&from_itemidx=1&count=3&nolastread=1#wechat_redirect
https://mp.weixin.qq.com/s/pxKrjw_5NTdZfHOKCkwn8w